# ğŸ” VeriFlow: Structuralâ€“Semanticâ€“Executable Verification for LLM-generated Low-Code Workflows

**VeriFlow** is a lightweight verification framework for **LLM-generated low-code workflow systems** such as [n8n](https://n8n.io).  
It aims to bridge human-language task specifications and formal workflow validation through a hybrid pipeline combining structural analysis, semantic intent recognition, and sandbox-level executability simulation.
It provides **formal-inspired consistency checking** across three complementary dimensions:

- ğŸ§© **Structural** â€“ graph integrity and soundness  
- ğŸ’¡ **Semantic** â€“ intent alignment and node-type adequacy (rule + LLM hybrid)  
- âš™ï¸ **Executable** â€“ sandbox-based simulation and reachability validation  

The framework also includes **visualization** tools for workflow DAGs and a **batch evaluation CLI** for large-scale benchmarks.

VeriFlow is intended for researchers, workflow designers, and developers building or evaluating LLM-generated automations.

---

## ğŸŒ Overview

```
              Natural Language Prompt
                         â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                     â”‚
ğŸ¤– Option A                              âœï¸ Option B
LLM Workflow Generation                 Human-written Workflow
(gen_workflows)                         (gold.json)
      â”‚                                     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                Workflow JSON (n8n)
                         â†“
           Intent Extraction (LLM + Rule)
                         â†“
Structural â€” Semantic â€” Executable Verification
                         â†“
                JSON Report + Visualization
```

**Veriflow** bridges low-code workflows and formal verification by:
- Supporting two workflow input paths (LLM-generated or human-written), merging into the same verification pipeline.
- Extracting **directed acyclic graph (DAG)** structures from n8n workflows;
- Computing **multi-criteria structural metrics**;
- Checking **semantic alignment** via rule-based and LLM-assisted intent recognition;
- Executing workflows in a **safe sandbox** (no external API calls);
- Producing detailed **JSON reports** and **graphical DAG visualizations**.

---

## ğŸ”§ LLM-based Workflow Generation
Veriflow now includes an integrated module gen_workflows to generate n8n workflows directly from natural-language prompts, enabling automatic creation of benchmark datasets:
```
Prompt File (W5.txt)
        â†“
gen_workflows (LLM-based generator)
        â†“
Generated Workflows under bench/GenLLM/W5/
        â†“
veriflow verify / bench
```

## ğŸ§  Core Features

| Category                     | Description                                                                                                                |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| **Structural analysis**      | Connectivity, acyclicity, orphan-ratio, out-degree balance, and exit coverage.                                             |
| **Semantic checking**        | Hybrid rule + LLM mode for intent extraction (trigger, action, order, etc.).                                               |
| **Executability simulation** | Sandbox execution without network calls; detects missing parameters or unreachable nodes.                                  |
| **Hybrid scoring**           | Weighted aggregation `Overall = Î±Â·S + Î²Â·M + Î³Â·E` with normalized weights.                                                  |
| **Batch benchmarking**       | Evaluate multiple workflows under `bench/`; export per-case reports and CSV summaries.                                     |
| **Visualization**            | Generate publication-quality DAGs with rounded nodes, shadows, and highlighted execution paths.                            |
| **LLM Workflow Generation**  | Generate n8n workflows from prompts using veriflow.cli gen-workflows, producing structured benchmarks under bench/GenLLM/. |

---

## ğŸ“¦ Installation

### 1. Clone the repository
```bash
git clone https://github.com/ahzm/veriflow.git
cd veriflow
```

### 2. Create environment
```bash
conda env create -f environment.yml
conda activate veriflow
```

#### Dependencies:
- python=3.10
- networkx, matplotlib, pandas, typer, rich, openai, tiktoken

## Usage
### 0.  Generate workflows from prompts (Optional)
You can automatically generate n8n workflows from natural-language prompts:
```bash
python -m veriflow.cli gen-workflows \
  --prompts bench/GenLLM/prompts/W5.txt \
  --out bench/GenLLM/W5 \
  --overwrite
```
This produces structured workflow cases:
```
bench/GenLLM/W5/
  â”œâ”€â”€ W5_01/
  â”‚   â”œâ”€â”€ prompt.txt
  â”‚   â””â”€â”€ W5_01.json
  â”œâ”€â”€ W5_02/
  â”‚   â”œâ”€â”€ prompt.txt
  â”‚   â””â”€â”€ W5_02.json
  ...
```
These generated workflows can then be validated using verify or bench.

### 1. Verify a single workflow
Runs structural, semantic, and executability checks on one workflow.
```bash
python -m veriflow.cli verify \
  --input bench/T001/gold.json \
  --prompt "$(cat bench/T001/prompt.txt)" \
  --use-llm --sandbox --report experiments/results/T001_detail.json -v
```
#### Output Example
```
StructuralScore:   0.99
SemanticScore:     1.00
ExecutabilityScore:1.00
Overall:           1.00
[ok] wrote report to experiments/results/T001_detail.json
```

### 2. Visualize a workflow DAG
VeriFlow can generate DAG diagrams from workflow JSON files.
Below is an example visualization generated using:
```bash
python scripts/plot_dag.py \
  -i bench/T001/gold.json \
  -o experiments/results/T001_dag.png
```
<p align="center">
  <img src="experiments/results/T001_dag.png" alt="Workflow DAG example" width="700">
</p>

### 3. Verify a bench of workflows
Runs batch verification and exports CSV + detailed reports.
```bash
python -m veriflow.cli bench \  
  --glob "bench/GenLLM/W20C/*/*.json" \ 
  --out experiments/results/GenLLM_W20C.csv \      
  --use-llm \
  --sandbox \
  --dump-details
```
 
## ğŸ§© Architecture

```
veriflow/
â”œâ”€â”€ veriflow/                   # Core framework
â”‚   â”œâ”€â”€ cli.py                  # Main CLI entry (verify / bench commands)
â”‚   â”œâ”€â”€ structural/             # Structural validation
â”‚   â”‚   â”œâ”€â”€ checker.py          # Static schema checking
â”‚   â”‚   â””â”€â”€ schema.py           # Workflow schema definitions
â”‚   â”œâ”€â”€ semantic/               # Semantic consistency
â”‚   â”‚   â”œâ”€â”€ intent_extractor.py # Intent extraction
â”‚   â”‚   â””â”€â”€ matcher.py          # keyword matching
â”‚   â”œâ”€â”€ generator/              # Produce n8n JSON workflows from prompts
â”‚   â”‚   â””â”€â”€ genllm.py           # LLM-based workflow generation
â”‚   â”œâ”€â”€ executable/             # Executability validation
â”‚   â”‚   â”œâ”€â”€ sandbox.py          # validate workflow in sandbox
â”‚   â”‚   â””â”€â”€ dryrun.py           # Dry-run simulation
â”‚   â””â”€â”€ utils/                  # Shared helpers
â”‚       â”œâ”€â”€ io.py               # JSON & figure I/O utilities
â”‚       â”œâ”€â”€ logger.py           # unified logging configuration
â”‚       â””â”€â”€ graph.py            # Build and traverse workflow DAG
â”‚
â”œâ”€â”€ bench/                      # VeriFlow-Bench dataset
â”‚   â””â”€â”€ T001/                   # Example task
â”‚       â”œâ”€â”€ prompt.txt          # Natural language prompt
â”‚       â””â”€â”€ gold.json           # Ground-truth workflow
â”‚
â”œâ”€â”€ experiments/                # Experimental results & configs
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ report.csv          # Aggregated scores
â”‚       â””â”€â”€ score_plot.png      # Visualization
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ plot_dag.py             # Plot DAG
â”‚   â””â”€â”€ plot_results.py         # Plot S/M/E/Overall charts
â”‚
â”œâ”€â”€ environment.yml             # Reproducible environment
â”œâ”€â”€ Makefile                    # Shortcut commands
â”œâ”€â”€ LICENSE                     # MIT License
â””â”€â”€ README.md                   # Project overview and usage
```

## ğŸ“ˆ Example Report Structure
```json
{
  "scores": { "S": 0.99, "M": 1.0, "E": 1.0, "Overall": 1.0 },
  "issues": [],
  "struct_detail": {
    "connected_ratio": 1.0,
    "acyclic": 1.0,
    "orphan_ratio": 0.0,
    "final_S": 0.99
  },
  "semantic_detail": {
    "intent_conf": 0.92,
    "source": "rule+llm",
    "intent": { "need_email": true, "need_http": true, "need_schedule": true }
  },
  "exec_detail": {
    "executed_nodes_readable": ["Schedule Trigger", "HTTP Request", "Email"],
    "runtime_ok": 1.0
  }
}
```

## ğŸ“Š Benchmarks

VeriFlow includes the **GenLLM** benchmark, containing more than **700 LLM-generated workflows**.  
Among these, **690 workflows** form the evaluation subset used in our experiments.
(The remaining workflows include auxiliary cases for tool debugging and are not part of the main evaluation.)

The benchmark is constructed from structured natural-language prompt sets:
- **Wk**:   k unconstrained prompts (e.g., W10, W20, W60, W100)  
- **WkC**: constrained prompts with nested conditions, multi-trigger logic, and stricter behavioral requirements

Each prompt corresponds to one generated n8n workflow under:
```
bench/GenLLM/W30/
bench/GenLLM/prompts/W30.txt
```
These datasets support large-scale evaluation of structural, semantic, and executable verification.

## ğŸ§­ Milestones (Implemented)
- âœ… Structural metrics with robustness for small DAGs
- âœ… Hybrid semantic mode (rule + LLM)
- âœ… LLM-based workflow synthesis (veriflow.generator.genllm + CLI: gen-workflows)
- âœ… Sandbox execution validator (parameter & reachability checks)
- âœ… Unified CLI with JSON export and verbose diagnostics
- âœ… Publication-grade DAG plotting with highlighted paths
- âœ… Logging and I/O utilities (veriflow.utils)
- âœ… Benchmark suite support (bench/*)

## ğŸ“š Citation
If you use VeriFlow in scientific publications, please cite:

```bibtex
@misc{veriflow2025,
  title = {VeriFlow: A Framework for Multi-Dimensional Verification of LLM-generated Low-Code Workflows},
  year = {2025},
  url = {https://github.com/ahzm/veriflow}
}
```